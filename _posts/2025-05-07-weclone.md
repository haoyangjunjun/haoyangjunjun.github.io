---
layout:     post
title:      "weclone部署记录"
subtitle:   "尝试制作赛博好氧菌"
date:       2025-05-07 12:00:00
author:     "hangyangjun"
header-img: "img/weclone.png"
tags:
    - 笔记
    - 记录
    - 学习
    - AI
    - 微调
    - docker
---

尝试制作赛博好氧菌
微信有足够的数据量
或者考虑深夜小作文日记笔记之类的

weclone项目
记得之前搞过ai，cuda装过了

安装uv(https://docs.astral.sh/uv/)一个Python 包和项目经理

git克隆后目录

powershell：
uv venv .venv --python=3.10

因为用的windows环境，只能试试了

.venv\Scripts\activate
**激活虚拟环境**

uv pip install --group main -e . 
安装
还挺慢

不过这个多线程下载挺爽的

python -c "import torch; print('CUDA是否可用:', torch.cuda.is_available());"

检测环境------true

安装FlashAttention，加速训练和推理：uv pip install flash-attn --no-build-isolation

数据准备
数据预处理
这一部分稍后再搞
先用测试数据集试试

模型下载
git lfs install
跟踪和管理大文件

git clone https://www.modelscope.cn/Qwen/Qwen2.5-7B-Instruct.git

下载模型也挺慢的，而且还没有进度条。。。。

好吧，我收回我的话，速度其实挺快的，而且竟然不走代理。。。


```
这些参数是一个典型的 AI 模型训练配置（尤其是针对大语言模型或类似任务的微调），通常用于控制训练过程的行为。以下是每个参数的详细解释：

基础训练配置
stage: "sft"
表示当前训练阶段是 Supervised Fine-Tuning (SFT)，即有监督微调。常见于指令微调（如 LLaMA、ChatGLM 等模型的指令跟随能力训练）。
dataset: "wechat-sft"
使用的数据集名称，这里可能是自定义的微信对话数据集或其他指令跟随数据集。
dataset_dir: "./dataset/res_csv/sft"
数据集存放的本地路径，通常包含训练样本（如 CSV、JSON 或文本文件）。
use_fast_tokenizer: true
是否使用快速分词器（如 Hugging Face 的 FastTokenizer），牺牲少量精度以加速分词过程。
LoRA 配置（低秩适配）
LoRA（Low-Rank Adaptation）是一种轻量级微调技术，通过低秩矩阵近似参数更新，减少计算量。

lora_target: "q_proj,v_proj"
指定在哪些网络层应用 LoRA。这里可能是注意力机制中的 Query 投影（q_proj） 和 Value 投影（v_proj） 层。
lora_rank: 4
LoRA 矩阵的秩（rank），值越小计算量越低，但可能牺牲表达能力。通常设为 4-64。
lora_dropout: 0.4
LoRA 层的 dropout 概率，防止过拟合（0.4 表示 40% 的神经元会被随机丢弃）。
优化器与正则化
weight_decay: 0.1
L2 正则化系数，惩罚大权重值以防止过拟合（0.1 是较强正则化）。
overwrite_cache: true
是否覆盖已缓存的预处理数据（如分词后的结果），设为 true 可强制重新处理数据。
训练批处理与梯度
per_device_train_batch_size: 8
每个 GPU/CPU 上的训练批次大小（batch size），影响内存占用和训练速度。
gradient_accumulation_steps: 4
梯度累积步数。模拟更大的批次大小（实际 batch_size = 8 × 4 = 32），缓解显存不足问题。
学习率调度
lr_scheduler_type: "cosine"
学习率调度器类型，cosine 表示余弦退火，学习率随训练过程平滑变化（先下降后回升）。
learning_rate: 1e-4
初始学习率（0.0001），常见于微调任务。
warmup_ratio: 0.1
学习率预热比例（前 10% 的训练步数中，学习率从 0 线性增长到 1e-4），避免初始震荡。
训练时长与日志
num_train_epochs: 3
训练轮数（3 轮遍历整个数据集）。
logging_steps: 10
每 10 步记录一次训练日志（如损失、学习率等）。
save_steps: 100
每 100 步保存一次模型检查点。
其他技术
cutoff_len: 256
文本截断长度（256 个 token），超长部分会被丢弃，影响上下文窗口大小。
plot_loss: true
是否绘制训练损失曲线（可视化工具如 TensorBoard 或 WandB）。
fp16: true
使用混合精度训练（FP16），减少显存占用并加速计算（需 GPU 支持）。
flash_attn: "fa2"
使用 Flash Attention 第 2 版（优化注意力计算的算法，显著提升速度并降低显存）。
总结
目标：通过 LoRA 轻量级微调一个语言模型，使其适应指令跟随任务（SFT 阶段）。
关键技术：LoRA、混合精度（FP16）、Flash Attention、余弦学习率调度。
适用场景：中等规模数据集（如微信对话数据），在单卡或多卡 GPU 上训练。
如果有特定参数需要进一步优化或解释，可以结合具体任务调整（如增大 lora_rank 或降低 lora_dropout）。
```

python weclone/train/train_sft.py
尝试训练，但是突然发现没有数据，嘿嘿🤣

聊天记录迁移还能出bug，微信真垃圾还得想办法
通过，关闭防火墙、禁用虚拟网卡、连接手机热点（宿舍WiFi有隔离）终于解决了
但是速度巨慢无比。

终于是迁移完了，差点给我跑步耽误了。

聊天记录导出工具：(https://github.com/xaoyaoo/PyWxDump)

导出的csv 文件夹放在./dataset目录


C:\Users\******\Documents\WeChat Files\**************2\Msg

7a792d8b1c514e5ba*****************57d21c9aedd

D:\下载\wxdump_work

再次运行python weclone/data/qa_generator.py

数据就搞好了，接下来就可以训练了
不过我这6G显存不知道能不能行呢

总之先试试：
**单卡训练**
python weclone/train/train_sft.py

好家伙，直接给显卡干满了
。。。。
然后就无了
报错了，研究研究

很明显爆显存了

uv pip install bitsandbytes


改了setting又报错，还不熟悉这些训练框架之类的，也不知道能不能改成4bit精度

还是换个模型试试吧

Qwen2.5-1.5B-Instruct
就挺好

git clone https://www.modelscope.cn/Qwen/Qwen2.5-1.5B-Instruct.git

再改一下setting

还是不行
重新处理数据试试

重启试试

没用。。。。。。

重新下载一遍模型试试
ok 成功了，好像是之前下载的时候出问题了。。。。。

貌似是训练完了，但是收敛的好像不太好
想再尝试，但是硬盘满了，而且训练时显存已经快爆了
安装
flash-attn总是失败
cuda删了下了12.6版本的试试

还是不行，已经到第二天了，暂时放弃

尝试使用浏览器demo简单推理
可以在这一步测试出合适的temperature、top_p值，修改settings.json的infer_args后，供后续推理时使用。

python weclone/eval/web_demo.py

终于运行出来了
而且回复速度超级快

虽然很智障，但是也能算个加减乘除
以及回复的语气有点意思，但是感觉也不是很像我

需要更多测试

Top-p采样值（Nucleus Sampling）

高创造性任务（如故事生成）：p=0.9 允许更多多样性。
低容错任务（如代码生成）：p=0.3~0.5 限制随机性。
极端值：
p=1：等同于贪心搜索（生成最可能的结果，但可能重复）。
p=0：随机选择（无意义）。


温度系数（Temperature）

对话系统：T=0.7~0.9 平衡合理性与多样性。
诗歌生成：T=1.2~1.5 增加创造力。
事实性问答：T=0.3~0.5 避免错误。
极端值：
T=0：完全选择概率最高的token（等同于贪心搜索）。
T=∞：完全随机选择（无意义）。

需要确定性（如代码生成）：低温 + 低Top-p。
需要多样性（如故事生成）：高温 + 高Top-p。


你好
用go语言写helloworld
今晚玩什么
上号
吃什么
几点玩
[其他测试题](https://docs.zetatechs.com/llm-test/#_4)

问了一堆问题，进行微调，感觉都不太聪明，也许是模型大小的限制吧，2：00了，白天再搞了，该碎觉了。

看了一眼，微信对话机器人的部署有点复杂，看来还得学一下docker